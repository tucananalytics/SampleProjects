{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50bd2faa",
   "metadata": {},
   "source": [
    "# Sumulation of product formulation design using Bayesian Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2fbc23",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "- Bayesian optimization is a sequential design strategy for global optimisation of “black-box” functions via intelligent exploration of the parameter space.\n",
    "- It builds a surrogate model for the objective and quantifies the uncertainty in that surrogate model using Gaussian process (GP) regression.\n",
    "- It then employs an acquisition function defined from this surrogate model to decide where to sample. \n",
    "- Gaussian process regression is underpinned by a kernel, which is chosen such that points that are closer have a large positive correlation, encoding the belief that they should have more similar function values than points that are far apart. \n",
    "- It is customary to explore different kernels, along with their associated parameters.\n",
    "- The process therefore  generates a sequence of (suggested) results/experiments as the optimization improves \n",
    "\n",
    "There are several libraries for Bayesian Optimization (e.g., see https://sheffieldml.github.io/GPyOpt/). This implementation was to improve understanding of the technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1074e359",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern,RationalQuadratic,RBF\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import minimize,  LinearConstraint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2387b068",
   "metadata": {},
   "source": [
    "Experimentation is simulated using a plynomial function. Typically, this should be an actual formulation (i.e., experiments in the lab) which is *expensive* both in terms of time and money. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fda5048",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def polynomial_aux(x,y,degree):\n",
    "    '''\n",
    "        the polynomial function\n",
    "        x - value of sles\n",
    "        y - value of lauric acid\n",
    "        degree - the degree of the polynomial, currently 1 - 4 \n",
    "    '''\n",
    "    cf\t= [513.8876003,485.5712164,-131.6215742]\n",
    "    cf2 = [866.6232174,668.6746113,-317.2022851,-457.7137891,-238.8347154]\n",
    "    cf3 = [-6142.274035,-13688.30946,12805.9489,74782.81504,-7834.368912,-122278.7583,1773.422826]\n",
    "    cf4 = [-283247.8119,76342.95751,777456.662,-609458.0096,-917419.5376,2086708.454,394646.3515,-2589721.103,34036.70983]\n",
    "    if degree == 1:\n",
    "        return x * cf[0] + cf[1] * y + cf[2]\n",
    "    if degree == 2:\n",
    "        return x * cf2[0] + y * cf2[1] + x * x * cf2[2] + y * y * cf2[3] + cf2[4]\n",
    "    if degree == 3:\n",
    "        return  x * cf3[0] + y * cf3[1] + x * x * cf3[2] + y * y * cf3[3] + pow(x, 3) * cf3[4] + pow(y, 3) * cf3[5] + cf3[6]\n",
    "    if degree == 4:\n",
    "        return x * cf4[0] + y * cf4[1] + pow(x, 2) * cf4[2] + pow(y,2) * cf4[3] + pow(x, 3) * cf4[4] + pow(y, 3) * cf4[5] +  pow(x, 4) * cf4[6] + pow(y, 4) * cf4[7] + cf4[8]  \n",
    "\n",
    "## the main polynomial function\n",
    "def polynomial(x,y,degree):\n",
    "    '''\n",
    "        the polynomial function\n",
    "        x - value of sles\n",
    "        y - value of lauric acid\n",
    "        degree - the degree of the polynomial, currently 1 - 5 where 5 is the max of 3 & 4\n",
    "    '''\n",
    "    if degree >= 1 and degree <=4:\n",
    "        return polynomial_aux(x,y,degree)\n",
    "    if degree == 5:\n",
    "        return max(polynomial_aux(x,y,3),polynomial_aux(x,y,4))\n",
    "    else: \n",
    "        raise Exception(\"Sorry, no degrees index greater than 5 (which is the maximum of 3 & 4) allowed\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab422b68",
   "metadata": {},
   "source": [
    "Generate the data grid that underpins the heathmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9f4185",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_datagrid(start1,end1,start2,end2,start3,end3,scale,total = 1):\n",
    "    '''\n",
    "    Creates a data grid of points within the sample space\n",
    "    for sles, lauric acid and CAPB\n",
    "    \n",
    "    Parameters\n",
    "    -----\n",
    "    start1 : the lower bound (of sles in this case)\n",
    "    end1 : the upper bound of (of sles in this case)\n",
    "    start2 : the lower bound (of lauric acid in this case)\n",
    "    end2 : the upper bound (of lauric acid in this case)\n",
    "    start3 : the lower bound (of capb in this case)\n",
    "    end3 : the upper bound (of capb in this case)\n",
    "    scale : determines the number of cells in the grid (approx. scale * scale * 0.16)\n",
    "    total : the constraint on the grid, which is 1 in this case\n",
    "    '''\n",
    "    range1 = (end1 - start1)\n",
    "    range2 = (end2 - start2)\n",
    "    scale1 = (scale * range1 / (range1 + range2)) \n",
    "    increment1 = (end1 - start1)/ scale1\n",
    "    increment2 = (end2 - start2) / (scale - scale1)\n",
    "    data_list = []\n",
    "    for value1 in np.arange(start1 + increment1,end1 , increment1):\n",
    "        for value2 in np.arange(start2 ,end2 , increment2):\n",
    "            val = value1 + value2\n",
    "            if val < total :\n",
    "                capb = total - val\n",
    "                if capb >= start3 and capb <= end3:\n",
    "                    data = {'Sles': value1, 'LauricAcid': value2, 'CAPB' : total - value1 - value2}\n",
    "                    data_list.append(data)    \n",
    "    return pd.DataFrame(data_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdb7155",
   "metadata": {},
   "source": [
    "Bayesian optimization processing class utilising *Expected Improvement* (EI) and a *Gussian Process* acquisition function. \n",
    " - EI is used to select the next design point in a design space, with the objective of maximizing performance. \n",
    " - The concept of expected improvement revolves around the idea of exploring the design space systematically and efficiently, in order to find the optimal solution.\n",
    " - It balances exploration vs exploitation while optimizing the function efficiently by maximizing the expected improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849e5726",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesianOptimizer():      \n",
    "    '''\n",
    "    A bayesian optmisation processing class\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    target_func : the function to be optimized (maximized)\n",
    "    x_init : initial x value\n",
    "    y_init : initial y value \n",
    "    n_iter : number of iterations\n",
    "    gp_kernel : the kernel to be used\n",
    "    dataframe : the data grid with sles,lauric acid, etc\n",
    "    '''\n",
    "    def __init__(self, target_func, x_init, y_init, n_iter,gp_kernel,dataframe):#\n",
    "        self.x_init = x_init\n",
    "        self.y_init = y_init\n",
    "        self.target_func = target_func\n",
    "        self.n_iter = n_iter\n",
    "        self.df = dataframe\n",
    "        self.gauss_pr = GaussianProcessRegressor(kernel=gp_kernel)\n",
    "        self.linear_constrinats = LinearConstraint([[1, 1, 1]], [1], [1])\n",
    "        self.best_samples = [ {\"Out_Sles\" : xs[0],\"Out_LAcid\" : xs[1],\"Out_CAPB\" : xs[2], \"Foam\": ys[0], \"EI\": 0, \"Sequence\": n+1} for xs,ys,n in zip(x_init, y_init,range(0,len(y_init)))]\n",
    "    \n",
    "    def _extend_prior_with_posterior_data(self, x,y):\n",
    "        self.x_init = np.append(self.x_init, np.array([x]), axis = 0)\n",
    "        self.y_init = np.append(self.y_init, np.array(y), axis = 0)\n",
    "        \n",
    "    def _get_expected_improvement(self, x_new):\n",
    "        # Estimate the Gaussian surrogate at the new trial data point   \n",
    "        mean_y_new, sigma_y_new = self.gauss_pr.predict(np.array([x_new]), return_std=True)\n",
    "        sigma_y_new = sigma_y_new.reshape(-1,1)\n",
    "        if sigma_y_new == 0.0:\n",
    "            return 0.0 \n",
    "        # calculate expected improvement    \n",
    "        mean_y = self.gauss_pr.predict(self.x_init)\n",
    "        max_mean_y = np.max(mean_y)\n",
    "        z = (mean_y_new - max_mean_y) / sigma_y_new\n",
    "        exp_imp = (mean_y_new - max_mean_y) * norm.cdf(z) + sigma_y_new * norm.pdf(z)        \n",
    "        return exp_imp\n",
    "        \n",
    "    '''\n",
    "    Given that SciPy only accepts minimisation problems, we flip the sign of the \n",
    "    objective function to effect a maximization. \n",
    "    \n",
    "    The parameter is the same as in _get_expected_improvement above\n",
    "    '''\n",
    "    def _get_negative_expected_improvement(self, x):\n",
    "        return -self._get_expected_improvement(x)\n",
    "            \n",
    "    def _get_next_probable_point(self):\n",
    "            min_ei = float(sys.maxsize)\n",
    "            x_optimal = None             \n",
    "            # evaluate points from the training set           \n",
    "            for x_start in [[sls,lac,capb]  for sls,lac,capb in zip(self.df['Sles'], self.df['LauricAcid'], self.df['CAPB'])]:\n",
    "                response = minimize(fun=self._get_negative_expected_improvement, x0=x_start, method='SLSQP', bounds=((0.3469, 0.8), (0.1, 0.3061) , (0.1,0.4) ) , constraints=self.linear_constrinats)\n",
    "                if response.fun < min_ei:\n",
    "                    min_ei = response.fun\n",
    "                    x_optimal = response.x       \n",
    "            return x_optimal, min_ei\n",
    "    \n",
    "    def fit(self):\n",
    "        self.gauss_pr.fit(self.x_init, self.y_init)\n",
    "\n",
    "    def optimize(self):\n",
    "        y_max_ind = np.argmax(self.y_init)\n",
    "        y_max = self.y_init[y_max_ind]\n",
    "        optimal_x = self.x_init[y_max_ind]\n",
    "        optimal_ei = 0\n",
    "        error = 0\n",
    "        prev_x = self.y_init[0]\n",
    "        for i in range(self.n_iter):\n",
    "            self.gauss_pr.fit(self.x_init, self.y_init)\n",
    "            x_next, ei = self._get_next_probable_point()\n",
    "            y_next = self.target_func(np.array([[x_next[0],x_next[1] ]]))  \n",
    "            self._extend_prior_with_posterior_data(x_next,[y_next])            \n",
    "            if y_next[0] > y_max:\n",
    "                y_max = y_next[0]\n",
    "                optimal_x = x_next\n",
    "                optimal_ei = ei\n",
    "            if i == 0:\n",
    "                #prev_x = x_next\n",
    "                optimal_ei = ei\n",
    "            else:\n",
    "                error = np.linalg.norm(prev_x - x_next)\n",
    "                prev_x = x_next \n",
    "            self.best_samples.append( {\"Out_Sles\" : x_next[0],\"Out_LAcid\" : x_next[1],\"Out_CAPB\" : x_next[2], \"Foam\": y_next[0], \"EI\": optimal_ei, \"Sequence\": len(self.y_init) } )      \n",
    "        return optimal_x, y_max\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e4b05f",
   "metadata": {},
   "source": [
    "Testing with some initial combinations \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90a90f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def response_function(xs):   \n",
    "    vals = [polynomial(x[0],x[1],5)  for x in xs]\n",
    "    return np.array(vals) \n",
    "\n",
    "def create_list_chunks(list_to_chunk,val):\n",
    "    ys = []\n",
    "    xs = list_to_chunk\n",
    "    while len(xs) > 0:\n",
    "        ys.append(xs[:val])\n",
    "        xs = xs[val:]\n",
    "    return ys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71acec31",
   "metadata": {},
   "source": [
    "Initialise kernels - see https://scikit-learn.org/stable/modules/gaussian_process.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d433ea80",
   "metadata": {},
   "outputs": [],
   "source": [
    "matern_kernel = 1.0 * Matern(length_scale=1.0, length_scale_bounds=(1e-1, 10.0), nu=1.5)\n",
    "rational_quadratic_kernel = 1.0 * RationalQuadratic(length_scale=1.0, alpha=0.1, alpha_bounds=(1e-5, 1e4))\n",
    "rbf_kernel = 1.0 * RBF(length_scale=1.0, length_scale_bounds=(1e-1, 10.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4cff9d",
   "metadata": {},
   "source": [
    "Bayesian Optimization Results From 4 Experiments: \n",
    "- Process is initialised with 4 experiments for the algorithm to suggest where the 5th should be \n",
    "- The suggestion is determined to be where the maximum expected improvement would be\n",
    "- I.e., for every possible input, how much is foam value expected to improve from current estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa97b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayes_opt_from_num(sles, lauricAcid, foam, rotate = 0, init_val = 4, max_exp = 8,scale=80,kernel = rational_quadratic_kernel,kernel_name = \"RationalQuadratic\"):\n",
    "    results = []    \n",
    "    result_filename = 'gp_results_rot'+str(rotate) + '_from'+ str(init_val)+ '.csv'\n",
    "    grid_file_name = kernel_name + '_gp_grid_results_rot'+ str(rotate) +'_from' + str(init_val) + '.csv'\n",
    "    if(init_val > 0 and init_val <= len(sles)):\n",
    "        inputs = [np.array(vls) for vls in create_list_chunks([[sls,lac,1-sls-lac] for sls,lac in zip(sles, lauricAcid)],init_val) ]\n",
    "        outputs = [vls for vls in create_list_chunks([[fm] for fm in foam],init_val) ]\n",
    "        df = generate_datagrid(0.3469, 0.8, 0.1, 0.3061, 0.1, 0.4,scale)\n",
    "        ## get the maximum foam value\n",
    "        max_faom = max([response_function([np.array([sls,lac])]) for sls,lac, in zip(df['Sles'], df['LauricAcid'])] )\n",
    "        for x_vls,y_vals,idx in zip(inputs,outputs, range(len(inputs)) ):\n",
    "            if(idx == 0):  \n",
    "                #fit the initial points\n",
    "                bopt = BayesianOptimizer(target_func=response_function, x_init=x_vls, y_init=y_vals, n_iter=1,gp_kernel=kernel,dataframe=df)\n",
    "                bopt.fit() \n",
    "                mean_header = 'GpInitMean_From' + str(init_val) \n",
    "                sd_header = 'GpInitStd_From' + str(init_val) \n",
    "                mean_and_sigma = [bopt.gauss_pr.predict(np.array([[sls,lac,capb]]), return_std=True)  for sls,lac,capb in zip(df['Sles'], df['LauricAcid'], df['CAPB'])] \n",
    "                df[mean_header] = np.asarray([x[0] for x in  mean_and_sigma], dtype=np.float32)\n",
    "                df[sd_header] = np.asarray([x[1] for x in  mean_and_sigma], dtype=np.float32)\n",
    "                #---\n",
    "                new_x_vls = x_vls\n",
    "                new_y_vls = y_vals\n",
    "                for vl in range(1,max_exp, 1):\n",
    "                    sequence = init_val + vl                    \n",
    "                    current_processing = {\"Rotation\" : rotate ,\"From\" : sequence ,  \"Length\" : len(x_vls), \"Kernel \": kernel_name}\n",
    "                    print('Processing: ', current_processing )\n",
    "                    #--------------------------------------------------------------\n",
    "                    # expected improvement from the GP fitted to the init_val data\n",
    "                    #--------------------------------------------------------------\n",
    "                    bopt = BayesianOptimizer(target_func=response_function, x_init=new_x_vls, y_init=new_y_vls, n_iter=1,gp_kernel=kernel,dataframe=df)\n",
    "                    bopt.optimize()\n",
    "                    #expected Improvment from each point in the grid\n",
    "                    exp_impv_header = 'ExpectedImpv_From' + str(sequence - 1) \n",
    "                    exp_impv = [bopt._get_expected_improvement(np.array([sls,lac,capb]))  for sls,lac,capb in zip(df['Sles'], df['LauricAcid'], df['CAPB'])] \n",
    "                    df[exp_impv_header] = np.asarray([x[0] for x in  exp_impv], dtype=np.float32)\n",
    "                    #-----------------------------------------------------\n",
    "                    #fit the next point\n",
    "                    #-----------------------------------------------------\n",
    "                    new_x_vls = bopt.x_init\n",
    "                    new_y_vls = bopt.y_init\n",
    "                    bopt.fit()\n",
    "                    bopt_mean_and_sigma = [bopt.gauss_pr.predict(np.array([[sls,lac,capb]]), return_std=True)  for sls,lac,capb in zip(df['Sles'], df['LauricAcid'], df['CAPB'])]       \n",
    "                    bopt_mean_header = 'GpBoptMean_From' + str(sequence) \n",
    "                    bopt_sd_header = 'GpBoptStd_From' + str(sequence) \n",
    "                    df[bopt_mean_header] = np.asarray([x[0] for x in  bopt_mean_and_sigma], dtype=np.float32)\n",
    "                    df[bopt_sd_header] = np.asarray([x[1] for x in  bopt_mean_and_sigma], dtype=np.float32)\n",
    "                    results += [{**current_processing, **value} for value in bopt.best_samples ]\n",
    "                    latest_foam = bopt.best_samples[-1]\n",
    "                    ##  stop processing if the maximum foam value has been found\n",
    "                    if(latest_foam['Foam'] >= max_faom[0]):\n",
    "                        print(\"Maximum foam value reached in sequence \" , sequence , \" for rotation \", rotate)\n",
    "                        break\n",
    "        df.to_csv(grid_file_name, encoding='utf-8', index=False, header=True)            \n",
    "    else:\n",
    "        raise Exception(\"The init_val value must be greater than 0 and less than or equal to \" + str(len(sles)) )\n",
    "    result_df = pd.DataFrame(results)\n",
    "    result_df.to_csv(result_filename, encoding='utf-8', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8241e2",
   "metadata": {},
   "source": [
    "Evaluating different initial combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d2f0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_sles = [0.8, 0.68892858, 0.62, 0.3469, 0.483349001, 0.5, 0.67632656, 0.5938776, 0.514433498, 0.3469]\n",
    "orig_lauricAcid = [0.1, 0.144428568, 0.1, 0.2531, 0.173492419, 0.1, 0.22367344, 0.3061224, 0.273877504, 0.3061224]\n",
    "orig_foam = [300, 300, 310, 250, 160, 140, 300, 275, 310, 140, 300, 300, 350, 250, 170, 105, 285, 350, 320, 140, 320, 270, 300, 200, 150, 130, 320, 350, 300, 130]\n",
    "\n",
    "## Average the 30 measured foam values \n",
    "def avg_foam (val = 3):\n",
    "    return [ (orig_foam[i] + orig_foam[i + 10] + orig_foam[i + 20])/val for i in range(len(orig_sles))]\n",
    "foam_n = avg_foam()\n",
    "\n",
    "#move the first ln elements of the list ot the back\n",
    "def rotate_list_at(list_to_rotate, ln):\n",
    "    if (len(list_to_rotate) > ln and ln > 0):\n",
    "        back = list_to_rotate[:ln]\n",
    "        front = list_to_rotate[ln:]        \n",
    "        return front + back\n",
    "    else:         \n",
    "        return list_to_rotate\n",
    "\n",
    "\n",
    "#generate results for all rotations, using all kernels\n",
    "def bayes_opt_for_all(rotation_limit):\n",
    "    if (rotation_limit >= 0 and rotation_limit <= len(orig_sles)):\n",
    "        for kernel, kernel_name in zip( [matern_kernel, rational_quadratic_kernel, rbf_kernel], ['Matern', 'RationalQuadratic', 'RBF'] ):\n",
    "            for n in range(rotation_limit):\n",
    "                rot_sles = rotate_list_at(orig_sles,n)\n",
    "                rot_lauricAcid = rotate_list_at(orig_lauricAcid,n)\n",
    "                rot_foam = rotate_list_at(foam_n,n)\n",
    "                bayes_opt_from_num(sles=rot_sles,lauricAcid= rot_lauricAcid, foam=rot_foam,rotate = n,scale=135, kernel=kernel,kernel_name=kernel_name)\n",
    "    else:\n",
    "        raise Exception(\"The rotation number must be at least 0 and less than \" + str(len(orig_sles)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d722b968",
   "metadata": {},
   "outputs": [],
   "source": [
    "## run the bayesian optimisation for all rotations\n",
    "bayes_opt_for_all(rotation_limit=10)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
